options(warn = 0)
warning = F
library(data.table)
library(dplyr)
library(corrplot)
library(lattice)
library(caret)
library('RANN')
library(knitr)
library(outliers)
cs.training <- fread("./dat/cs-training.csv", stringsAsFactors = FALSE)
options(warn = 0)
warning = F
library(data.table)
library(dplyr)
library(corrplot)
library(lattice)
library(caret)
library('RANN')
library(knitr)
library(outliers)
cs.training <- fread("../dat/cs-training.csv", stringsAsFactors = FALSE)
cs.test <- fread("../dat/cs-test.csv", stringsAsFactors = FALSE)
dim(cs.training)   # There are 150k obs. in the training set
dim(cs.test)   # There are 101.5k obs. in the test set
str(cs.training)   # Look at a sample to see what's going on
glimpse(cs.training)   # Nicer version of str
View(cs.training[sample(.N, 1000)])   # Look at a sample to see what's going on
str(cs.test)
setnames(cs.training, c("id", "SD", "RUUL", "Age", "no3059", "DebtRatio", "Income", "OpenCredit", "no90", "REloans", "no6089", "Dep"))
cs.training = cs.training[,.(id, SD, Age, RUUL, DebtRatio, Income, OpenCredit, REloans, Dep, no3059, no6089, no90)]
cs.training %>% head() %>% kable(row.names = FALSE)
cs.training %>% tail() %>% kable(row.names = FALSE)
hist(cs.training$SD, breaks = 2)
prop.table(table(cs.training$SD))   # 0.933 / 0.067
summary(cs.training)
colmax = sapply(cs.training[,-"id",with=F], max, na.rm=T)
normalized = scale(cs.training[,-"id",with=F], center = F, scale = colmax)
boxplot(normalized)
hist(cs.training$Age)
hist(cs.training$RUUL)
hist(cs.training$DebtRatio)
hist(cs.training$Income)
boxplot.stats(cs.training$Age)$out
set(cs.training, which(cs.training$Age == 0), "Age", as.integer(mean(cs.training$Age)))
qplot(data = cs.training,
x = Age,
geom="histogram",
binwidth = (max(cs.training$Age)-min(cs.training$Age))/10,
xlab = "Age",
fill=I("blue"),
col=I("red"),
alpha=I(0.2),
xlim=c(min(cs.training$Age), max(cs.training$Age)))
boxplot(cs.training$RUUL, main="Revolving Utilization of Unsecured Lines", horizontal = T)
cor(cs.training$RUUL, cs.training$SD, use = "pairwise.complete.obs")   # -0.0018
RUULstats <- boxplot.stats(cs.training$RUUL)$stats
data.table(stats=c('min','lower quartile','median','upper quartile','max'),
value=RUULstats)   %>% kable()
length(boxplot.stats(cs.training$RUUL)$out)   # 763
outlierReplace = function(dataframe, cols, rows, newValue = NA) {
if (any(rows)) {
set(dataframe, rows, cols, newValue)
}
}
outlierReplace(cs.training, "RUUL", which(cs.training$RUUL>RUULstats[5]), RUULstats[5])
qplot(data = cs.training,
x = RUUL,
geom="histogram",
binwidth = (RUULstats[5]-RUULstats[1])/30,
main = "Revolving Utilization of Unsecured Lines",
xlab = "RUUL",
fill=I("blue"),
col=I("red"),
alpha=I(0.2),
xlim=c(RUULstats[1], RUULstats[5]*1.05))
cor(cs.training$RUUL, cs.training$SD, use = "pairwise.complete.obs")   # 0.283004
boxplot(cs.training$DebtRatio, main="Debt Ratio", horizontal = T)
outlier(cs.training$DebtRatio)
cs.training[cs.training$DebtRatio == outlier(cs.training$DebtRatio),]   %>% kable()
length(boxplot.stats(cs.training$DebtRatio)$out)   # 31311 outliers in DebtRatio
sum(is.na(cs.training$Income))   # 29731 NA's in Income
DebtRatioStats <- boxplot.stats(cs.training$DebtRatio)$stats
outlierReplace(cs.training, "DebtRatio", which(cs.training$DebtRatio>DebtRatioStats[5]))
qplot(data = cs.training,
x = DebtRatio,
geom="histogram",
binwidth = (DebtRatioStats[5]-DebtRatioStats[1])/30,
main = "Debt Ratio",
xlab = "DebtRatio",
fill=I("blue"),
col=I("red"),
alpha=I(0.2),
xlim=c(DebtRatioStats[1], DebtRatioStats[5]*1.05))
boxplot(cs.training$Income, main="Monthly Income", horizontal = T)
length(boxplot.stats(cs.training$Income)$out)   # 4879
IncomeStats <- boxplot.stats(cs.training$Income)$stats
data.table(stats=c('min','lower quartile','median','upper quartile','max'),
value=IncomeStats)   %>% kable()
outlierReplace(cs.training, "Income", which(cs.training$Income>IncomeStats[5]), IncomeStats[5])
qplot(data = cs.training,
x = Income,
geom="histogram",
binwidth = (IncomeStats[5]-IncomeStats[1])/15,
main = "Income",
xlab = "Income",
fill=I("blue"),
col=I("red"),
alpha=I(0.2),
xlim=c(IncomeStats[1], IncomeStats[5]*1.05))
boxplot(cs.training$OpenCredit, main="NumberOfOpenCreditLinesAndLoans", horizontal = T)
length(boxplot.stats(cs.training$OpenCredit)$out)
qplot(data = cs.training,
x = OpenCredit,
geom="histogram",
binwidth = (max(cs.training$OpenCredit)-min(cs.training$OpenCredit))/50,
xlab = "OpenCredit",
fill=I("blue"),
col=I("red"),
alpha=I(0.2),
xlim=c(min(cs.training$OpenCredit), max(cs.training$OpenCredit)))
boxplot(cs.training$REloans, main="NumberRealEstateLoansOrLines", horizontal = T)
length(boxplot.stats(cs.training$REloans)$out)   # 793
head(sort(cs.training$REloans, decreasing = T), 15)
cs.training[cs.training$REloans == outlier(cs.training$REloans),]   %>% kable()
REloansStats <- boxplot.stats(cs.training$REloans)$stats
outlierReplace(cs.training, "REloans", which(cs.training$REloans>20), 20)
hist(cs.training$REloans, breaks=20)
boxplot(cs.training$Dep, main="NumberOfDependents", horizontal = T)
length(boxplot.stats(cs.training$Dep)$out)
head(sort(cs.training$Dep, decreasing = T), 10)
outlierReplace(cs.training, "Dep", which(cs.training$Dep>10), 10)
hist(cs.training$Dep, breaks=10)
boxplot(cs.training$no3059, main="NumberOfTime30-59DaysPastDueNotWorse", horizontal = T)
head(sort(cs.training$no3059, decreasing = T), 100)
outlierReplace(cs.training, "no3059", which(cs.training$no3059>20), 0)
max(cs.training$no3059)
hist(cs.training$no3059, breaks=13)
outlierReplace(cs.training, "no6089", which(cs.training$no6089>20), 0)
max(cs.training$no6089)
hist(cs.training$no6089, breaks=11)
outlierReplace(cs.training, "no90", which(cs.training$no90>20), 0)
max(cs.training$no90)
hist(cs.training$no90, breaks=17)
summary(cs.training)
sum(is.na(cs.training))   # 64966
sum(is.na(cs.training$DebtRatio))   # 31311; introduced above by replacing outliers
sum(is.na(cs.training$Income))   # 29731
sum(is.na(cs.training$Dep))   # 3924
cs.training$Income[is.na(cs.training$Income)] <- as.integer(mean(cs.training$Income, na.rm=TRUE))
cs.training$Dep[is.na(cs.training$Dep)] <- as.integer(mean(cs.training$Dep, na.rm=TRUE))
# cs.training.temp <- as.data.frame(cs.training[, -c("id", "SD")])
# preProcValues <- preProcess(cs.training.temp, method = c("knnImpute"))
# trainImputed <- predict(preProcValues, cs.training.temp)
cs.training$DebtRatio[is.na(cs.training$DebtRatio)] <- mean(cs.training$DebtRatio, na.rm=TRUE)
summary(cs.training)
cs.training$LateDays <- cs.training[,no3059] * 30 +
cs.training[,no6089] * 60 +
cs.training[,no90] * 90
sum(cs.training$Income==0)   # 1634
cs.training$Income[cs.training$Income==0] = as.integer(mean(cs.training$Income))
cs.training$logIncome <- log(cs.training[,Income])
cs.training$Debt <- cs.training[,DebtRatio] * cs.training[,Income]
cs.training$Slack <- cs.training[,Income] - cs.training[,Debt]
summary(cs.training)
M <- cor(cs.training[,-"id",with=F], use = "pairwise.complete.obs")
round(M,2)   %>% kable()
corrplot(M, method="color")
highCorr  <- findCorrelation(M[-1,-1], 0.75, names=T)
highCorr   # "Income"   "LateDays"
cs.training <- cs.training[, -c("Income", "no90")]
M <- cor(cs.training[,-"id",with=F], use = "pairwise.complete.obs")
corrplot(M, method="color")
nzv <- nearZeroVar(cs.training)
colnames(cs.training)[nzv]   # "no6089"
cs.training <- cs.training[,-nzv,with=F]  # removing nzv columns
str(cs.training)
cs.training <- cs.training[, -"id"]
trans = preProcess(cs.training[, -"SD"],
method=c("center", "scale"))
train_normalized = predict(trans, cs.training)
head(train_normalized, 20)   %>% kable()
fwrite(train_normalized, file = "..dat/Train.csv")
library(data.table)
library(caret)
library(RANN)
library(dplyr)
# Read the training data
data <- fread("../dat/cs-training.csv", stringsAsFactors = FALSE)
# Changing to shorter column names and change order
setnames(data,
c("id", "SD", "RUUL", "Age", "no3059", "DebtRatio", "Income", "OpenCredit", "no90", "REloans", "no6089", "Dep"))
data = data[, .(SD, Age, RUUL, DebtRatio, Income, OpenCredit, REloans, Dep, no3059, no6089, no90)]
summary(data)
# Replace age==0 & income==0 with median
median_Age = as.integer(median(data$Age)) # 52
median_Income = as.integer(median(data$Income, na.rm=TRUE)) # 5400
data$Age[data$Age == 0] <- median_Age
data$Income[data$Income == 0] <- median_Income
# Replace outliers
outlierReplace = function(dataframe, cols, rows, newValue = NA) {
if (any(rows)) {
set(dataframe, rows, cols, newValue)
}
}
RUULmax <- boxplot.stats(data$RUUL)$stats[5] # 1.35
outlierReplace(data, "RUUL", which(data$RUUL > RUULmax), RUULmax)
DebtRatio_max <- boxplot.stats(data$DebtRatio)$stats[5] # 1.9
median_DebtRatio = median(data$DebtRatio) # 0.4
outlierReplace(data, "DebtRatio", which(data$DebtRatio > DebtRatio_max), median_DebtRatio)
IncomeStats_max <- boxplot.stats(data$Income)$stats[5] # 15500
outlierReplace(data, "Income", which(data$Income > IncomeStats_max), IncomeStats_max)
outlierReplace(data, "REloans", which(data$REloans > 20), 20)
outlierReplace(data, "Dep", which(data$Dep > 10), 10)
outlierReplace(data, "no3059", which(data$no3059 > 20), 0)
outlierReplace(data, "no6089", which(data$no6089 > 20), 0)
outlierReplace(data, "no90", which(data$no90 > 20), 0)
# Impute NA's Dep with median
data$Dep[is.na(data$Dep)] <- 0
# Writing to file for doing regression on the NA values in Income
# See GiveMeSomeCredit.ipynb
fwrite(data, file = "../dat/Train1.csv")
# Reading back the imputed file
data <- fread("../dat/Train2.csv", stringsAsFactors = FALSE)
# Feature engineering
data$LateDays <- data[, no3059] * 30 + data[, no6089] * 60 + data[, no90] * 90
data$Debt <- data[, DebtRatio] * data[, Income]
data$Slack <- data[,Income] - data[,Debt]
# Looking at correlation matrix
M <- cor(data, use = "pairwise.complete.obs")
round(M,2)
# Removing correlated variables
data <- data[, -c("no3059", "no6089", "no90", "DebtRatio", "Debt")]
summary(data)
# Centralize & Scale
trans = preProcess(data[, -c("SD")], method=c("center", "scale"))
data_normalized = predict(trans, data)
data_normalized[, SD:= data[, SD]]
# Writing to file
fwrite(data_normalized, file = "../dat/Train3.csv")
# Balance training set
data_split <- split(data_normalized, as.factor(data_normalized$SD))
SD0 <- data_split$'0'
SD1 <- data_split$'1'
n <- nrow(SD1)
set.seed(42)
SD0_sample10k <- sample_n(SD0, n)
data_balanced <- rbind(SD0_sample10k, SD1)
data_balanced <- data_balanced[sample(2*n), ]
fwrite(data_balanced, file = "../dat/Train4.csv")
# Read the tests data
data <- fread("../dat/cs-test.csv", stringsAsFactors = FALSE)
# Changing to shorter column names and change order
setnames(data,
c("id", "SD", "RUUL", "Age", "no3059", "DebtRatio", "Income", "OpenCredit", "no90", "REloans", "no6089", "Dep"))
data = data[, .(id, Age, RUUL, DebtRatio, Income, OpenCredit, REloans, Dep, no3059, no6089, no90)]
summary(data)
# Replace age==0 & income==0 with median
data$Age[data$Age == 0] <- median_Age
data$Income[data$Income == 0] <- median_Income
# Replace outliers
outlierReplace(data, "RUUL", which(data$RUUL > RUULmax), RUULmax)
outlierReplace(data, "DebtRatio", which(data$DebtRatio > DebtRatio_max), median_DebtRatio)
outlierReplace(data, "Income", which(data$Income > IncomeStats_max), IncomeStats_max)
outlierReplace(data, "REloans", which(data$REloans > 20), 20)
outlierReplace(data, "Dep", which(data$Dep > 10), 10)
outlierReplace(data, "no3059", which(data$no3059 > 20), 0)
outlierReplace(data, "no6089", which(data$no6089 > 20), 0)
outlierReplace(data, "no90", which(data$no90 > 20), 0)
# Impute NA's in Dep with median
data$Dep[is.na(data$Dep)] <- 0
# Writing to file for doing regression on the NA values in Income
fwrite(data, file = "../dat/Test1.csv")
# Reading back the imputed file
data <- fread("../dat/Test2.csv", stringsAsFactors = FALSE)
# Feature engineering
data$LateDays <- data[, no3059] * 30 + data[, no6089] * 60 + data[, no90] * 90
data$Debt <- data[, DebtRatio] * data[, Income]
data$Slack <- data[,Income] - data[,Debt]
# Removing correlated variables
data <- data[, -c("no3059", "no6089", "no90", "DebtRatio", "Debt")]
summary(data)
# Centralize & Scale
trans = preProcess(data[, -c("id")], method=c("center", "scale"))
data_normalized = predict(trans, data)
data_normalized[, id:= data[, id]]
# Writing to file
fwrite(data_normalized, file = "../dat/Test3.csv")
library(data.table)
library(tidyverse)
# unbalanced dataset
val.dt <- fread("../dat/val.csv", stringsAsFactors = FALSE)
dim(val.dt[y == 0])
dim(val.dt[y == 1])
val.dt %>%
ggplot(aes(y_hat)) +
geom_density() +
facet_grid(y ~ .)
x <- c()
y <- c()
for (i in seq(0, 1, 0.1)){
TN <-  dim(val.dt[y == 0 & y_hat < i])[1]
FP <-  dim(val.dt[y == 0 & y_hat >= i])[1]
FN <-  dim(val.dt[y == 1 & y_hat < i])[1]
TP <-  dim(val.dt[y == 1 & y_hat >= i])[1]
Sensitivity <-  TP / (FN + TP)
Specificity <-  TN / (TN + FP)
x <- c(x, 1 - Specificity)
y <- c(y, Sensitivity)
}
plot(x, y)
# balanced dataset
val.dt <- fread("../dat/val2.csv", stringsAsFactors = FALSE)
dim(val.dt[y == 0])
dim(val.dt[y == 1])
val.dt %>%
ggplot(aes(y_hat)) +
geom_density() +
facet_grid(y ~ .)
x <- c()
y <- c()
for (i in seq(0, 1, 0.1)){
TN <-  dim(val.dt[y == 0 & y_hat < i])[1]
FP <-  dim(val.dt[y == 0 & y_hat >= i])[1]
FN <-  dim(val.dt[y == 1 & y_hat < i])[1]
TP <-  dim(val.dt[y == 1 & y_hat >= i])[1]
Sensitivity <-  TP / (FN + TP)
Specificity <-  TN / (TN + FP)
x <- c(x, 1 - Specificity)
y <- c(y, Sensitivity)
}
plot(x, y)
plot(x, y, type="l")
plot(x, y, type="l")
# unbalanced dataset
val.dt <- fread("../dat/val.csv", stringsAsFactors = FALSE)
dim(val.dt[y == 0])
dim(val.dt[y == 1])
val.dt %>%
ggplot(aes(y_hat)) +
geom_density() +
facet_grid(y ~ .)
val.dt %>%
ggplot(aes(y_hat)) +
geom_density() +
facet_grid(y ~ ., ncol=2)
val.dt %>%
ggplot(aes(y_hat)) +
geom_density() +
facet_wrap(y ~ ., ncol=2)
val.dt %>%
ggplot(aes(y_hat)) +
geom_density() +
facet_grid(y ~ ., ncol=2)
# unbalanced dataset
val.dt <- fread("../dat/val.csv", stringsAsFactors = FALSE)
dim(val.dt[y == 0])
dim(val.dt[y == 1])
val.dt %>%
ggplot(aes(y_hat)) +
geom_density() +
facet_wrap(y ~ ., ncol=2)
val.dt %>%
ggplot(aes(y_hat)) +
geom_density() +
facet_wrap( ~ y, ncol=2)
x <- c()
y <- c()
for (i in seq(0, 1, 0.1)){
TN <-  dim(val.dt[y == 0 & y_hat < i])[1]
FP <-  dim(val.dt[y == 0 & y_hat >= i])[1]
FN <-  dim(val.dt[y == 1 & y_hat < i])[1]
TP <-  dim(val.dt[y == 1 & y_hat >= i])[1]
Sensitivity <-  TP / (FN + TP)
Specificity <-  TN / (TN + FP)
x <- c(x, 1 - Specificity)
y <- c(y, Sensitivity)
}
plot(x, y, type="l")
# balanced dataset
val.dt <- fread("../dat/val2.csv", stringsAsFactors = FALSE)
dim(val.dt[y == 0])
dim(val.dt[y == 1])
val.dt %>%
ggplot(aes(y_hat)) +
geom_density() +
facet_wrap( ~ y, ncol=2)
